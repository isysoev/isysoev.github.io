<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Ivan Sysoev -> Child-driven, machine-guided</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="../../assets/main/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="../../css/agency.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
            <div class="container-fluid">
                <a class="project-title" href="../../index.html#child-driven-machine-guided">To main</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    <i class="fas fa-bars ms-1"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link" href="#about">About</a></li>
                        <li class="nav-item"><a class="nav-link" href="#design">Design</a></li>
<!--                         <li class="nav-item"><a class="nav-link" href="#explorations">Explorations</a></li> -->
                        <li class="nav-item"><a class="nav-link" href="#findings">Findings</a></li>
                        <li class="nav-item"><a class="nav-link" href="#publications">Publications</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- About -->
        <section class="page-section" id="about">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Child-driven, machine-guided</h2>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/child-driven-machine-guided/visual-abstract.jpg" alt="..." />
                    </div>
                </div>
                <div class = "row">
                    <p class = "text-center text-muted">
                        <i>MIT Media Lab, 2017-2020</i><br>
                        <i>Roles: Project lead; Concept; Design; Development; Research</i><br>
                        <i>Collaborators: James Gray, Susan Fine, Sneha Makini. Advisor: Deb Roy</i>
                    </p>
                    <p class = "text-left"> 
                        Several educational approaches, such as <a class="inline-href" href="https://en.wikipedia.org/wiki/Constructionism_(learning_theory)">constructionism</a>, rely on child-driven learning activities. These activities can be intrinsically motivating, supportive of learners’ senses of agency and self-efficacy, and meaningfully connected to the learners’ lives — all of which is beneficial for learning. However, to be effective, child-driven learning requires <a class="inline-href" href="https://en.wikipedia.org/wiki/Instructional_scaffolding">scaffolding</a> (i.e. guidance). With learners working on their own projects, scaffolding often needs to be highly individualized, and thus labor-intensive. Progress in artificial intelligence poses an intriguing, and currently open, question on whether scaffolding can to some extent be automated.
                    </p>
                    <p class = "text-left"> 
                        In this project, we investigated incorporating automatic scaffolding into a constructionist-like app for early literacy learning.
                    </p>
                </div>
            </div>
        </section>
        <!-- Design -->
        <section class="page-section bg-light" id="design">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Design</h2>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/child-driven-machine-guided/speechblocks.jpg" alt="..." />
                    </div>
                </div>
                <div class="row">
                    <p class = "text-left"> 
                        The image above shows our app, <i>SpeechBlocks II</i>. The child makes words to get images corresponding to them. These words and images can be used to assemble pictures on the canvas (this interaction was inspired by <a class="inline-href" href="https://dl.acm.org/doi/abs/10.1145/3392063.3394392">PictureBlocks</a> by my colleague Sneha Makini). We experimented with using letter-based and phoneme-based blocks (more on this in <a class="inline-href" href="phoneme-blocks.html">the corresponding section</a>).
                    </p>
                    <p class = "text-left"> 
                        If children so desire, they can spell on their own both real words and non-words. But if they would like to spell a specific word, they could communicate that word to the system using <a class="inline-href" href="what-would-you-like-to-spell.html">one of five methods</a>: word bank, speech recognition, text recognition, network of semantic associations, and invented spelling interpretation (more on them on the dedicated page). The system would then guide children <a class="inline-href" href="https://en.wikipedia.org/wiki/Phoneme">phoneme-by-phoneme</a>, as shown in the video below. The phoneme-by-phoneme approach is used to help children develop key literacy skills (<a class="inline-href" href="https://en.wikipedia.org/wiki/Phonological_awareness">phonological awareness</a> and the mapping between phonemes and <a class="inline-href" href="https://en.wikipedia.org/wiki/Grapheme">graphemes</a>).
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <div class="embed-responsive embed-responsive-16by9 centerline-graphics">
                            <iframe class="embed-responsive-item youtube" src="https://www.youtube.com/embed/8YqajATf4Uo" allowfullscreen></iframe>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- Explorations -->
<!--         <section class="page-section" id="explorations">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Explorations</h2>
                </div>
            </div>
        </section> -->
        <!-- Findings -->
        <section class="page-section" id="findings">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Findings</h2>
                </div>
                <div class="row text-left">
                    <p>
                        The main study for this project was conducted at a public charter school in Boston area. 25 children, 4-5 years old, used SpeechBlocks in their class throughout the semester, and 32 children continued their learning as usual and were used for comparison. The reader can find more details about this study and its findings in our <a class="inline-href" href="assets/publications/Sysoev-et-al-CompEdu-Child-Driven-Machine-Guided.pdf">Computers & Education paper</a> listed below.
                    </p>
                    <h3 class="section-heading text-uppercase">Engagement, agency, self-efficacy</h3>
                    <p>
                        We observed notable engagement with the app - for example, in one case children played for 30 minutes and still wanted to go on; they asked if they could take the app home. Children proudly displayed their work to both adults and peers, made plans regarding what to build, and wanted to keep their creations and bring them home. Some children kicked, stomped, jumped in excitement and exclaimed, <i>“Yay!”</i> after finishing words they intended to build. Some were also proud to gather many objects on one page as evidence of their hard work. One interesting manifestation of self-efficacy was children voluntarily challenging themselves to spell difficult words. E.g., one child put his headphones down to avoid hearing the prompts. After completing the word, he proudly announced, <i>“I did it all by myself!”</i>
                    </p>
                    <h3 class="section-heading text-uppercase">Collaborative play</h3>
                    <p>
                        Entirely on their own, children engaged in various forms of collaborative play. They borrowed each other's ideas or elaborated on them in their creations. For example, one child built a scene showing panthers encroaching on some tigers, and showed it to a friend. The friend liked the idea and built his own panther attacking a giraffe. The first child then “one-upped” her friend by building a crocodile that, according to her, devoured all the other animals. 
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/child-driven-machine-guided/shared-play.jpg" alt="..." />
                    </div>
                </div>
                <div>
                    <p>
                        They also came up with small games, such as <i>“I’m going to build your name, and you build my name. Then, let’s both build Abigail’s name”</i>. In this way, they supported each other's engagement.
                    </p>
                    <p> 
                        But most importantly, children directly helped each other to spell words. We saw several “leader-follower” pairs in which a more skilled child built some words and another one repeated them after her/him. These pairs talked about what they made, how they made it, and what they should do next. If the “follower” experienced any difficulties in the spelling process, the "leader" assisted him/her. This behavior created opportunities for shared learning.
                    </p>
                    <p>
                        Automatic scaffolding appeared to support these interactions. By fostering children’s autonomy, it allowed them to fluently respond to emerging ideas. The scaffolding machinery also made it relatively easy to explain to peers what to do by referring to the machine prompts.
                    </p>
                    <h3 class="section-heading text-uppercase">What did children do?</h3>
                    <p>
                        Though children were able to use both scaffolded and non-scaffolded modes, about 85% of words were constructed with the help of scaffolding. Most of the remaining constructions were non-words (e.g. random combinations of letters). Scaffolding mechanisms thus played an important role in children's play. We saw three key categories of play with the app, roughly corresponding to three categories of players.
                    </p>
                    <p>
                        <b>Word crafting</b> focused on the creation of words apparently for the sake of it. A very popular category of such words were names. Some players experimented with long words, such as TRANSPORTATION. Word crafters enjoyed collecting the words they created on the canvas.
                    </p>
                    <p>
                        <b>Imaginative play</b> had two primary forms: making static scenes (such as ones on the picture below) and enactment, in which children used sprites akin to physical toys. For example, a child built several wild animals, then put a crocodile over them and enact the crocodile devouring the other animals by moving it back and forth while saying, “Chomp! Chomp!”. These forms of play were often combined by building a scene and then enacting some action within it. Children explored a diverse range of themes, such as family, home life, city, jungle and space. Among their sources of inspiration were the topics they studied in the classroom and the works of their peers.
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-md-10 col-lg-8">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/child-driven-machine-guided/imaginative-play-scenes.jpg" alt="..." />
                    </div>
                </div>
                <div class="row text-left">
                    <p id="story-back-and-forth">
                        Children typically didn't work towards implementing a pre-defined narrative; rather, the story they conveyed through SpeechBlocks evolved as they tinkered with the app. One good example is how the ninja scene (#9 on the picture above) was created. At first, the child built two ninjas and said, <i>“They are father and son. They are practicing”</i>. She then expressed a desire to give them weapons, and used invented spelling recognition to create SOD (sword). Then she resorted to speech recognition to build SHIELD. Afterwards, she tapped on the sword to see the related words, picked DAGGER and gave it to the small ninja. This was followed by a long exploration of the semantic association network, until she stumbled upon the word PRISONER. This discovery prompted her to exclaim, <i>“I’m going to make a villain to fight them!”</i>, which led to the complete scene. 
                    </p>
                    <p>
                        For both imaginative players and word crafters, scaffolding was very important. Building scenes like the ones above required to make on the order of 10 words. In a study conducted when our app didn't have scaffolding, there were just 10 real words made by all children throughout the entire study, aside from their names and copies of words from the facilitating materials. Thus, automatic scaffolding dramatically increased the number of words children could make per session, and by means of that enabled sophisticated forms of play. By the end of our study, active players learned to use scaffolding almost completely autonomously. The teachers noted this autonomy and appreciated the resulting reduction in their workload. There was, however, one category of players for which our scaffolding appeared to be insufficient.
                    </p>
                    <p>
                        <b>Impulsive exploration</b> was characterized by a lack of systematicity: while long-term plans were voiced by the players, they were rarely followed through. Instead, children focused on short-term rewards - emotional, social and cognitive - that could be gained through interaction with the system. Such play was often unproductive from the literacy standpoint.
                    </p>
                    <!-- <p>
                        Here is an example of such play. A child’s attention was drawn by a peer saying that he is going to make ten copies of BATMAN. <i>“I wanna make ten Batmans [too]!”</i> exclaimed the child. He was instantly distracted from that goal by something else but later returned to it. However, he did not pay any attention to the scaffolding prompts and just randomly dragged blocks into slots. The scaffolding system rejected his choices. The child attributed it to a bug in the app and gave up. When his peer asked him about building BATMAN, he said, <i>“Batman is not working”</i>. The peer responded, <i>“You just gotta spell it! Can you hear it?”</i> The peer then started to demonstrate how to use the scaffolding to build the word. The impulsive explorer, however, did not listen to him and was looking away. Therefore, the friend recruited his attention by asking him to pick the next block. Together, they eventually managed to complete the word.
                    </p> -->
                    <p>
                        Impulsive explorers often passionately expressed a desire to make something ambitious, but quickly moved away from these plans or were easily discouraged by the challenges. They were usually interested in the outcome, but not the process, of word building - so they sometimes wanted their peers or the researchers to build words for them. They often didn't pay attention to directions - be it our demos, the feedback of the scaffolding system, or advice given by a peer or a facilitator - even when these directions were aimed at helping them achieve their own goals. They tried to “brute-force” word constructions by trying random actions. Finally, impulsive explorers also showed a tendency to use the app interface in unintended ways. They randomly tapped and swiped, tinkered with the hardware buttons (e.g., power off), tried to intentionally cause bugs, spent entire sessions making a single sprite big and small and used the OCR interface to “take pictures” of each other.
                    </p>
                    <p>
                        Impulsive exploration was more often exhibited by kids with lower phonological awareness and executive functioning. These attributes were also associated with lower levels of learning from the app. It is likely that the distracted behaviors impeded learning. A question remains whether improvements to the design can alleviate these problem. One possibility is that it was a by-product of our scaffolding system being not sufficiently adaptive to the child's skill level, making intended activities were too difficult for children with lower skills. In the future, we plan to investigate whether a more adaptive scaffolding could help with the situation.
                    </p>
                </div>
            </div>
        </section>
        <!-- Publications -->
        <section class="page-section bg-light" id="publications">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Publications</h2>
                </div>
                <div class="row text-left">
                    <p>
                        <b>Sysoev, I.</b>, Gray, J. H., Fine, S., Makini, S.P. & Roy, D. (2022). Child-driven, machine-guided: Automatic scaffolding of constructionist-inspired early literacy play. <i>Computers & Education</i>. <a href="../../assets/publications/Sysoev-et-al-CompEdu-Child-Driven-Machine-Guided.pdf">pdf</a>
                    </p>
                    <p>
                        <b>Sysoev, I.</b> (2020). <i>Digital Expressive Media for Supporting Early Literacy through Child-Driven, Scaffolded Play.</i> (Chapters 3 and 6) Doctoral dissertation, MIT Media Lab. <a href="../../assets/publications/Sysoev-Dissertation-2020-Early-Literacy-through-Child-Driven-Scaffolded-Play.pdf">pdf</a>
                    </p>
                </div>
            </div>
        </section>
        <section class="page-section">
            <div class="container">
                <div class="row justify-content-center">               
                    <a class="col-md-4 btn btn-primary btn-xl text-uppercase" type="button" href="../../index.html#child-driven-machine-guided">To main</a>
                </div>
            </div>
        </section>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="../../js/agency.js"></script>
    </body>
</html>
