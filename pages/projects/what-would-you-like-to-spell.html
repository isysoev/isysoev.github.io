<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Ivan Sysoev -> What would you like to spell</title>
        <!-- Favicon-->
        <link rel="icon" type="image/x-icon" href="../../assets/main/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="../../css/agency.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
            <div class="container-fluid">
                <a class="project-title" href="../../index.html#what-would-you-like-to-spell">To main</a>
                <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    <i class="fas fa-bars ms-1"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav text-uppercase ms-auto py-4 py-lg-0">
                        <li class="nav-item"><a class="nav-link" href="#about">About</a></li>
                        <li class="nav-item"><a class="nav-link" href="#design">Design</a></li>
<!--                         <li class="nav-item"><a class="nav-link" href="#explorations">Explorations</a></li> -->
                        <li class="nav-item"><a class="nav-link" href="#findings">Findings</a></li>
                        <li class="nav-item"><a class="nav-link" href="#publications">Publications</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- About -->
        <section class="page-section" id="about">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">What would you like to spell?</h2>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/what-would-you-like-to-spell/poster.jpg" alt="..." />
                    </div>
                </div>
                <div class = "row">
                    <p class = "text-center text-muted">
                        <i>MIT Media Lab, 2018-2019</i><br>
                        <i>Roles: Project lead; Concept; Design; Development; Research</i><br>
                        <i>Collaborators: James Gray, Sneha Makini, Susan Fine. Advisor: Deb Roy</i>
                    </p>
                    <p class = "text-left"> 
                        Children acquire the basics of literacy at the age when playful learning is particularly important. We created <a class="inline-href" href="child-driven-machine-guided.html">an early literacy app</a> (see below) to build upon the appeal of open-ended, expressive play. In this app, children can make whatever words they like and compose scenes out of these words and images associated with them. To produce optimal learning while remaining scalable, we incorporated automatic scaffolding into it. The scaffolding system guides children through building of the words that <i>they</i> choose to make. But this requires the system to "know" what are these words.
                    </p>
                    <div class="row justify-content-center">
                        <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                            <img class="img-fluid centerline-graphics" src="../../assets/projects/child-driven-machine-guided/speechblocks.jpg" alt="..." />
                        </div>
                    </div>
                    <p class = "text-left"> 
                        In this project, we investigated five mechanisms for doing that: word bank, speech recognition, text recognition, network of semantic associations, and invented spelling interpretation.
                    </p>
                </div>
            </div>
        </section>
        <!-- Design -->
        <section class="page-section bg-light" id="design">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Design</h2>
                </div>
                <div class="row">
                    <h3 class="section-heading text-uppercase">Word bank (WB)</h3>
                    <p class = "text-left"> 
                         Word bank is a simple collection of words arranged under categories. We selected words to align with children's common interests observed in previous studies, such as names and cartoon characters. In our choice of words, we also considered which objects can function well together (e.g. household items and family members).
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <div class="embed-responsive embed-responsive-16by9 centerline-graphics">
                            <iframe class="embed-responsive-item youtube" src="https://www.youtube.com/embed/4la1FTOF8y8" allowfullscreen></iframe>
                        </div>
                    </div>
                </div>
                <div class="row">
                    <h3 class="section-heading text-uppercase">Speech recognition (ASR)</h3>
                    <p class = "text-left"> 
                         Speech recognition allows the child to directly tell the system what s/he would like to make. But since the ASR on children's voices is not very robust, we complemented it with a UI feature: the system shows a list of candidate words, and the child can select one by tapping on it. The long-eared fox on the recognition screen helps children to see the status of the system (e.g. processing, success, failure), and provides a backstory helping to explain recognition errors (the fox is old - it has a beard - and thus it cannot hear very well). Previous research showed that such backstories help children to be more patient about the imperfections of learning systems.
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <div class="embed-responsive embed-responsive-16by9 centerline-graphics">
                            <iframe class="embed-responsive-item youtube" src="https://www.youtube.com/embed/_j-ckulquQw" allowfullscreen></iframe>
                        </div>
                    </div>
                </div>
                <div class="row">
                    <h3 class="section-heading text-uppercase">Text recognition (OCR)</h3>
                    <p class = "text-left"> 
                         Text recognition allows children to "grab" interesting words from their environments and books.
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <div class="embed-responsive embed-responsive-16by9 centerline-graphics">
                            <iframe class="embed-responsive-item youtube" src="https://www.youtube.com/embed/f47UvWBvAgU" allowfullscreen></iframe>
                        </div>
                    </div>
                </div>
                <div class="row">
                    <h3 class="section-heading text-uppercase">Semantic association network (SAN)</h3>
                    <p class = "text-left"> 
                         Semantic association network allowed the child to see words related to other words in their scenes. For instance, the picture below shows the associations to the word "dagger" that popped up after tapping on the dagger in the scene. The child can explore the network of associations in-depth by tapping on these icons - the associations for that word will then be shown. Tapping on an association will also reveal a button for spelling it. 
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/what-would-you-like-to-spell/semantic-associations.jpg" alt="..." />
                    </div>
                </div>
                <div class="row">
                    <h3 class="section-heading text-uppercase">Invented spelling interpretation (ISI)</h3>
                    <p class = "text-left"> 
                         Invented spelling is a fascinating phenomenon when children come up with their own ways to spell words based on their developing understanding of their phonetic structure and the relationships between sounds and letters. For instance, "fish" could be spelled as FES (where the name of the letter E stands for its sound), and "cat" could be spelled as KT (omitting the medial vowel and representing the sound [k] as K). Our system interprets such spellings and suggests candidate words that they might represent.
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <div class="embed-responsive embed-responsive-16by9 centerline-graphics">
                            <iframe class="embed-responsive-item youtube" src="https://www.youtube.com/embed/i-5eCcBQi74" allowfullscreen></iframe>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <!-- Explorations -->
<!--         <section class="page-section" id="explorations">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Explorations</h2>
                </div>
            </div>
        </section> -->
        <!-- Findings -->
        <section class="page-section" id="findings">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Findings</h2>
                </div>
                <div class="row">
                    <p>
                        Evaluation of the input mechanisms was part of a study examining <a class="inline-href" href="child-driven-machine-guided.html">child-driven, machine-guided</a> approach to early literacy learning. It occurred at a public charter school in Boston area. 25 children used SpeechBlocks in their class throughout the semester. The reader can find more details about this study and its findings in our <a class="inline-href" href="assets/publications/Sysoev-et-al-CompEdu-Child-Driven-Machine-Guided.pdf">Computers & Education paper</a>.
                    </p>
                    <h3 class="section-heading text-uppercase">Usage patterns</h3>
                    <p>
                        Though children were able to use both scaffolded and non-scaffolded modes, about 85% of words were constructed with the help of scaffolding. Children had difficulties using invented spelling interpreter, which as a result contributed to only ~6% of words. The fractions of words originated from semantic associations (~21.5%), speech recognition (~20%),  word bank (~18%) and text recognition (~16.5%) were approximately equal. Different children used these mechanisms in very different proportions, but the approximately equal overall usage of the four suggests that each of them was valuable in its own way.
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-md-10 col-lg-8">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/what-would-you-like-to-spell/usage-patterns.jpg" alt="..." />
                    </div>
                </div>
                <div class="row">
                    <h3 class="section-heading text-uppercase">Inputs' roles</h3>
                    <p>
                        Here is an example of scene construction using different input mechanisms. At first, the child built two ninjas and said, <i>“They are father and son. They are practicing”</i>. She then expressed a desire to give them weapons and used invented spelling recognition to create SOD (sword). Then she resorted to speech recognition to build SHIELD. Afterwards, she tapped on the sword to see the related words, picked DAGGER and gave it to the small ninja. This was followed by a long exploration of the semantic association network, until she stumbled upon the word PRISONER. This discovery prompted her to exclaim, <i>“I’m going to make a villain to fight them!”</i>, which led to the complete scene.
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-md-10 col-lg-8">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/analyzing-open-ended-play/timeline-of-a-scene-construction.jpg" alt="..." />
                    </div>
                </div>
                <div>
                    <p>
                        This sequence is illustrative of the roles that were generally served by different input mechanisms. We saw three main roles:
                    </p>
                    <p>
                        <b>Deliver words that player had in mind</b>. It was fulfilled particularly well by speech recognition. In our example, the child wanted to build SHIELD, and was able to accomplish it by using ASR. Children also resorted to speech recognition when they saw something interesting built by their peers, and wanted to make something similar. For example, one child built a scene showing panthers encroaching on some tigers, and showed it to a friend. The friend liked the idea and used ASR to build his own panther attacking a giraffe. The first child then “one-upped” her friend by using ASR to build a crocodile that, according to her, devoured all the other animals. 
                    </p>
                </div>
                <div class="row justify-content-center">
                    <div class="col-12 col-sm-10 col-md-8 col-lg-6">
                        <img class="img-fluid centerline-graphics" src="../../assets/projects/child-driven-machine-guided/shared-play.jpg" alt="..." />
                    </div>
                </div>
                <div>
                    <p>
                        <b>Help the player come up with ideas</b>. It was fulfilled particularly well by the association network. In the ninja example, the child appeared to ran out of ideas when she started to use the associations. She went through a long sequence starting with SWORD: SWORD -> WARRIOR -> HERO -> BATMAN -> DRAGON -> UNICORN -> CENTAUR -> GOBLIN -> WARRIOR -> HERO -> SOLDIER -> PRISONER - before she stumbled upon PRISONER, and that gave her a new idea on what to build, one she was very excited about.
                    </p>
                    <p>
                        <b>Be a fallback option</b>. The "high-tech" modes of input, such as speech recognition or text recognition, were far from being perfectly reliable. On such occasions, childen could resort to using word bank, which was simple and robust, while still having plenty of interesting words to build.
                    </p>
                    <h3 class="section-heading text-uppercase">Speech recognition was valuable</h3>
                    <p>
                        We were originally concerned that due to low quality of existing ASR systems on children's voices, the speech recognition input would be unusable. But children ended up using it successfully - partially because of the decision to show multiple recognition candidates, partially because of their own persistence. When the ASR failed to understand them, they patiently repeated their request for up to 6 times. This persistence also indirectly indicates the value of the system to them.
                    </p>
                    <p>
                        Two interesting things were observed with respect to ASR usage. First, children tended to speak to the system in sentences, e.g. <i>"Mr. Fox, please give me a GORILLA"</i>. Second, they treated Mr. Fox (the avatar of the system) as a living character, talking to him politely, asking him to do things (<i>“Mr. Fox, what time it is?”</i>, <i>“Mr. Fox, finish off (turn off) the tablet!</i>”), asking us about his abilities (<i>"Can he fly?"</i>), encouraging him when ASR failed to deliver correct result (<i>“Oh no! Mr. Fox, we need you! Mr. Fox, spell FIRE!”</i>) and appreciating his work when the result was correct (<i>"Mr. Fox, you busted it out!"</i> (apparently in the sense "produced"), <i>"Fox, I love you"</i>). These observations may be useful in designing interfaces for open-ended speech interaction for children.
                    </p>
                    <h3 class="section-heading text-uppercase">Invented spelling interpretation was hard to use</h3>
                    <p>
                        We only saw one child who consistently and purposefully built words using this method. For example, she used SR to make STAR, HR - to make CHAIR (note how she used the name of the letter H - [eɪtʃ] – to represent the sound [tʃ]). Other children typically just randomly arranged blocks in the input box until by chance they stumbled upon an output that they liked.
                    </p>
                    <p>
                        Here is some speculation as to why it might have been the case. First, it appears that many children didn't have sufficient phonological skills to identify the needed sounds. For example, during the demo period, a child couldn't identify the initial sound in BATMAN, saying "BATMAN starts with BATMAN". When asked to identify the last sound in a BOAT, he answered with the first sound ([b]), even when asked to try again. Second, children rarely removed blocks from the word box, even when they tried out multiple blocks in search for the correct sound. For instance, while trying to spell BOMB, a child first represented the sound [ɑ] as A, then O, and ended with BAO. Such scenarios led the interpreter astray. Finally, children occasionally put suitable blocks, but in the wrong order. The knowledge of spelling direction is not always firmly established at this age.
                    </p>
                    <p>
                        Given the proliferation of invented spellings in <a class="inline-href" href="tinkering-with-words.html#word-crafting">our studies with older children</a>, it is possible that this input method would work much better for older ages.
                    </p>
                    <h3 class="section-heading text-uppercase">Text recognition was problematic</h3>
                    <p>
                        Though children were excited about using text recognition, it was often associated with frustration, confusion and distraction. First, there were various issues with picking up words: (1) children holding the camera sideways relative to the text, or holding it too close to focus, or putting the tablet on top of the text; (2) players having a poor grip and shaking the tablet, which disrupted the camera's focus; (3) reflective surfaces producing glare; (4) child-oriented materials often containing highly stylized and decorative fonts; (5) words written by teachers on the board being underlined or smudged.
                    </p>
                    <p>
                        Second, children eagerly spelled the results of OCR errors, such as: CALE (for CUTE), DRAGO (for DRAGON), RZONT, FADER, LOORM, HEELS (for WHEELS), SOO, ODA. Since pre-literate children don't know what words actually "say", that might lead to confusion.
                    </p>
                    <p>
                        Finally, OCR was quite distracting for some. The most notable issue was "picture-taking". The user interface of OCR had a freeze button, intended to allow children to put down the bulky tablet and pick words. However, some children used this button to obtain short-lived portraits of their friends. Another unintended activity was to use the interface like camera-obscura to look around through it. Children also created a game in itself from picking up words, without spelling or even hearing them: just pointing at words around the classroom, waiting until they turn green and moving on. Still another activity was to explore the texts via hearing the words, but never attempting to spell them. While the last activity might have some literacy value, it is disconnected from the primary purpose of the system. These distractions were likely the reason why the week OCR was introduced, the number of spelled words per child fell nearly 20% compared to the previous week, and never returned to that level.
                    </p>
                </div>
            </div>
        </section>
        <!-- Publications -->
        <section class="page-section bg-light" id="publications">
            <div class="container">
                <div class="row text-center">
                    <h2 class="section-heading text-uppercase">Publications</h2>
                </div>
                <div class="row text-left">
                    <p>
                        <b>Sysoev, I.</b> (2020). <i>Digital Expressive Media for Supporting Early Literacy through Child-Driven, Scaffolded Play.</i> (Chapters 3 and 6.5) Doctoral dissertation, MIT Media Lab. <a href="../../assets/publications/Sysoev-Dissertation-2020-Early-Literacy-through-Child-Driven-Scaffolded-Play.pdf">pdf</a>
                    </p>
                </div>
            </div>
        </section>
        <section class="page-section">
            <div class="container">
                <div class="row justify-content-center">               
                    <a class="col-md-4 btn btn-primary btn-xl text-uppercase" type="button" href="../../index.html#what-would-you-like-to-spell">To main</a>
                </div>
            </div>
        </section>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="../../js/agency.js"></script>
    </body>
</html>
